{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IrXIYEprhdl5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrXIYEprhdl5",
        "outputId": "c902c14c-1e93-4d59-adc1-7201f75dbe53"
      },
      "outputs": [],
      "source": [
        "# On installe les bibliothèques nécessaires, notamment pour le TFT et l'agent RL\n",
        "!python -m pip install --upgrade pip setuptools wheel\n",
        "!pip install pandas numpy scikit-learn tensorflow gymnasium stable-baselines3 google-colab pytorch_lightning pytorch-forecasting pandas-ta pytorch-lightning -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IxGDgwELQIkP",
      "metadata": {
        "id": "IxGDgwELQIkP"
      },
      "source": [
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 0 : INSTALLATION ET IMPORTATION DES BIBLIOTHÈQUES\n",
        "# ------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd7bb55",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upkvW7f6SClr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "upkvW7f6SClr",
        "outputId": "938fa744-568d-4ee3-cb04-49fff6b0e20a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas_ta as ta\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import DQN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m8rnTc2Ngihj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "m8rnTc2Ngihj",
        "outputId": "9b8dc5aa-034b-472a-9019-2053c485dafe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Monter Google Drive pour accéder aux données ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================================================================\n",
        "# PARTIE 1 : CHARGEMENT ET INGÉNIERIE DES CARACTÉRISTIQUES (FEATURES)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- PARTIE 1 : Chargement et préparation des données ---\")\n",
        "\n",
        "# --- 1.1 Chargement et combinaison des fichiers CSV ---\n",
        "folder_path = '/content/drive/MyDrive/Global Stock Market (2008-2023)/*.csv' # Adaptez le chemin si nécessaire\n",
        "all_files = glob.glob(folder_path)\n",
        "df_list = [pd.read_csv(filename) for filename in all_files]\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# --- 1.2 Filtrage et nettoyage initial ---\n",
        "ticker_valide = '^GSPC'  # S&P 500\n",
        "df_filtered = df[df['Ticker'] == ticker_valide].copy()\n",
        "print(f\"Nombre de lignes trouvées pour le ticker '{ticker_valide}': {len(df_filtered)}\")\n",
        "\n",
        "# Garder les colonnes essentielles et gérer les dates\n",
        "df_processed = df_filtered[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "df_processed['Date'] = pd.to_datetime(df_processed['Date'])\n",
        "df_processed.sort_values('Date', inplace=True)\n",
        "df_processed.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# --- 1.3 Ingénierie des caractéristiques pour le TFT ---\n",
        "print(\"Ajout des indicateurs techniques et caractéristiques temporelles...\")\n",
        "# Indicateurs techniques via pandas-ta\n",
        "df_processed.ta.sma(length=20, append=True)  # Moyenne mobile simple\n",
        "df_processed.ta.rsi(length=14, append=True)  # Relative Strength Index\n",
        "df_processed.ta.bbands(length=20, append=True) # Bandes de Bollinger\n",
        "\n",
        "# Caractéristiques basées sur la date\n",
        "df_processed['day_of_week'] = df_processed['Date'].dt.dayofweek\n",
        "df_processed['month'] = df_processed['Date'].dt.month\n",
        "df_processed['year'] = df_processed['Date'].dt.year\n",
        "\n",
        "# Gérer les valeurs NaN créées par les indicateurs (remplissage vers l'arrière)\n",
        "df_processed.fillna(method='bfill', inplace=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# PARTIE 2 : PRÉDICTION AVEC LE TEMPORAL FUSION TRANSFORMER (TFT)\n",
        "# ==============================================================================\n",
        "print(\"\\n--- PARTIE 2 : Prédiction avec le Temporal Fusion Transformer (TFT) ---\")\n",
        "\n",
        "# --- 2.1 Formatage des données pour Pytorch Forecasting ---\n",
        "print(\"Formatage des données pour le TFT...\")\n",
        "df_processed['time_idx'] = range(len(df_processed))\n",
        "df_processed['group'] = ticker_valide # Identifiant de la série temporelle\n",
        "\n",
        "# --- 2.2 Création du TimeSeriesDataSet ---\n",
        "max_encoder_length = 60  # Utiliser les 60 derniers jours\n",
        "max_prediction_length = 1 # Pour prédire le jour suivant\n",
        "\n",
        "# Séparer les données pour l'entraînement et la validation du TFT\n",
        "training_cutoff = df_processed['time_idx'].max() - (max_prediction_length * 365) # Garder 1 an pour validation\n",
        "\n",
        "training_data = TimeSeriesDataSet(\n",
        "    df_processed[lambda x: x.time_idx <= training_cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Close\",\n",
        "    group_ids=[\"group\"],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[\"group\"],\n",
        "    time_varying_known_reals=[\"time_idx\", \"day_of_week\", \"month\", \"year\"],\n",
        "    time_varying_unknown_reals=[\n",
        "        'Open', 'High', 'Low', 'Volume', 'SMA_20', 'RSI_14',\n",
        "        'BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BBB_20_2.0', 'BBP_20_2.0'\n",
        "    ],\n",
        "    target_normalizer=GroupNormalizer(groups=[\"group\"], transformation=\"softplus\"),\n",
        ")\n",
        "\n",
        "validation_data = TimeSeriesDataSet.from_dataset(training_data, df_processed, predict=True, stop_randomization=True)\n",
        "\n",
        "# Création des DataLoaders\n",
        "batch_size = 128\n",
        "train_dataloader = training_data.to_dataloader(train=True, batch_size=batch_size, num_workers=2)\n",
        "val_dataloader = validation_data.to_dataloader(train=False, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# --- 2.3 Entraînement du modèle TFT ---\n",
        "print(\"Entraînement du modèle TFT...\")\n",
        "pl.seed_everything(42)\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=30,\n",
        "    accelerator=\"gpu\",\n",
        "    gradient_clip_val=0.1,\n",
        "    limit_train_batches=50,\n",
        "    callbacks=[early_stop_callback],\n",
        ")\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training_data,\n",
        "    learning_rate=0.03,\n",
        "    hidden_size=32,\n",
        "    attention_head_size=2,\n",
        "    dropout=0.1,\n",
        "    hidden_continuous_size=16,\n",
        "    loss=QuantileLoss(),\n",
        "    optimizer=\"Ranger\"\n",
        ")\n",
        "trainer.fit(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
        "\n",
        "# --- 2.4 Génération des prédictions et enrichissement du DataFrame ---\n",
        "print(\"Génération des prédictions du TFT pour tout le dataset...\")\n",
        "best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "full_dataloader = validation_data.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=2)\n",
        "raw_predictions, x = best_tft.predict(full_dataloader, mode=\"raw\", return_x=True)\n",
        "\n",
        "# On extrait la prédiction médiane (quantile 0.5, qui est à l'indice 3)\n",
        "predictions = raw_predictions[\"prediction\"][:, :, 3].numpy().flatten()\n",
        "\n",
        "# On crée un DataFrame avec les prédictions et on le fusionne\n",
        "tft_predictions_df = pd.DataFrame({\n",
        "    'tft_prediction': predictions\n",
        "}, index=df_processed.index[df_processed['time_idx'].isin(x['decoder_time_idx'].flatten())])\n",
        "\n",
        "df_final = df_processed.join(tft_predictions_df)\n",
        "df_final.dropna(inplace=True) # Supprimer les premières lignes sans prédictions\n",
        "df_final.set_index('Date', inplace=True)\n",
        "\n",
        "print(\"Aperçu du DataFrame final enrichi :\")\n",
        "print(df_final.head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# PARTIE 3 : APPRENTISSAGE PAR RENFORCEMENT AVEC DQN\n",
        "# ==============================================================================\n",
        "print(\"\\n--- PARTIE 3 : Apprentissage par Renforcement avec DQN ---\")\n",
        "\n",
        "# --- 3.1 Définition de l'environnement de Trading ---\n",
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, data: pd.DataFrame, initial_balance=10_000):\n",
        "        super().__init__()\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.action_space = spaces.Discrete(3) # 0: Hold, 1: Buy, 2: Sell\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(len(self.data.columns) + 2,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.current_step = 0\n",
        "        return self._get_observation(), {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        # On inclut les données du marché, la balance et les actions détenues\n",
        "        obs = np.concatenate([\n",
        "            self.data.iloc[self.current_step].values,\n",
        "            [self.balance],\n",
        "            [self.shares_held]\n",
        "        ]).astype(np.float32)\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        previous_net_worth = self.net_worth\n",
        "        current_price = self.data['Close'].iloc[self.current_step]\n",
        "\n",
        "        if action == 1 and self.balance > current_price: # Buy\n",
        "            self.shares_held += 1\n",
        "            self.balance -= current_price\n",
        "        elif action == 2 and self.shares_held > 0: # Sell\n",
        "            self.shares_held -= 1\n",
        "            self.balance += current_price\n",
        "\n",
        "        self.net_worth = self.balance + (self.shares_held * current_price)\n",
        "\n",
        "        # RÉCOMPENSE AMÉLIORÉE : changement de la valeur nette depuis l'étape précédente\n",
        "        reward = self.net_worth - previous_net_worth\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data) - 1\n",
        "\n",
        "        return self._get_observation(), reward, done, False, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f'Step: {self.current_step}, Net Worth: {self.net_worth:.2f}, Shares: {self.shares_held}, Balance: {self.balance:.2f}')\n",
        "\n",
        "# --- 3.2 Entraînement de l'agent DQN ---\n",
        "print(\"Entraînement de l'agent DQN...\")\n",
        "# Séparer les données pour l'entraînement et le test de l'agent RL\n",
        "train_size_rl = int(len(df_final) * 0.8)\n",
        "train_data_rl = df_final.iloc[:train_size_rl]\n",
        "test_data_rl = df_final.iloc[train_size_rl:]\n",
        "\n",
        "# Instancier l'environnement d'entraînement\n",
        "env_train = TradingEnv(data=train_data_rl)\n",
        "\n",
        "# Créer et entraîner le modèle DQN avec plus d'exploration\n",
        "model_dqn = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env_train,\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./dqn_tft_tensorboard/\",\n",
        "    exploration_fraction=0.5,\n",
        "    exploration_final_eps=0.05,\n",
        "    learning_rate=0.0005,\n",
        "    buffer_size=100_000\n",
        ")\n",
        "model_dqn.learn(total_timesteps=200_000, progress_bar=True)\n",
        "model_dqn.save(\"dqn_tft_trader\")\n",
        "\n",
        "# ==============================================================================\n",
        "# PARTIE 4 : ÉVALUATION ET BACKTESTING\n",
        "# ==============================================================================\n",
        "print(\"\\n--- PARTIE 4 : Évaluation sur les données de test ---\")\n",
        "\n",
        "# --- 4.1 Lancer le backtesting ---\n",
        "env_test = TradingEnv(data=test_data_rl)\n",
        "obs, info = env_test.reset()\n",
        "done = False\n",
        "\n",
        "print(\"\\n--- Début du Backtesting ---\")\n",
        "while not done:\n",
        "    action, _states = model_dqn.predict(obs, deterministic=True)\n",
        "    obs, reward, terminated, truncated, info = env_test.step(action)\n",
        "    done = terminated or truncated\n",
        "    env_test.render()\n",
        "\n",
        "# --- 4.2 Calculer le ROI final ---\n",
        "final_net_worth = env_test.net_worth\n",
        "initial_balance = env_test.initial_balance\n",
        "roi = ((final_net_worth - initial_balance) / initial_balance) * 100\n",
        "\n",
        "print(\"\\n--- Fin du Backtesting ---\")\n",
        "print(f\"Bilan Initial : {initial_balance:.2f} $\")\n",
        "print(f\"Bilan Final   : {final_net_worth:.2f} $\")\n",
        "print(f\"Retour sur Investissement (ROI) final : {roi:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5csdtYo64fPH",
      "metadata": {
        "id": "5csdtYo64fPH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
