{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae627224",
      "metadata": {
        "id": "ae627224"
      },
      "source": [
        "# Étape 1 : Prétraitement des Données\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2ef6d7",
      "metadata": {
        "id": "7a2ef6d7"
      },
      "source": [
        "### 1. Chargement et Sélection des Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb64fe1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb64fe1",
        "outputId": "f7a62495-3c6e-4873-e491-dfc382ac9a1f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m \u001b[38;5;66;03m# Pour trouver les fichiers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      7\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m folder_path  = \u001b[33m'\u001b[39m\u001b[33m/content/drive/MyDrive/Global Stock Market (2008-2023)/*.csv\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import glob # Pour trouver les fichiers\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "folder_path  = '/content/drive/MyDrive/Global Stock Market (2008-2023)/*.csv'\n",
        "all_files = glob.glob(folder_path)\n",
        "\n",
        "# Lire et combiner tous les fichiers CSV en un seul DataFrame\n",
        "df_list = []\n",
        "for filename in all_files:\n",
        "    df_list.append(pd.read_csv(filename))\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(df['Ticker'].unique())\n",
        "\n",
        "ticker_valide = '^GSPC'\n",
        "df_filtre = df[df['Ticker'] == ticker_valide].copy()\n",
        "print(f\"Nombre de lignes trouvées pour le ticker '{ticker_valide}': {len(df_filtre)}\")\n",
        "\n",
        "# Assurez-vous d'avoir des milliers de lignes maintenant !\n",
        "colonnes_necessaires = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
        "df_aapl = df_filtre[colonnes_necessaires].copy()\n",
        "\n",
        "df_aapl['Date'] = pd.to_datetime(df_aapl['Date'])\n",
        "df_aapl.sort_values('Date', inplace=True) # Très important de trier les données par date !\n",
        "df_aapl.set_index('Date', inplace=True)\n",
        "\n",
        "close_prices = df_aapl['Close'].values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371396ac",
      "metadata": {
        "id": "371396ac"
      },
      "source": [
        "### 2. Normalisation des Prix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ce7465f",
      "metadata": {
        "id": "9ce7465f"
      },
      "outputs": [],
      "source": [
        "# Normaliser les données entre 0 et 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(close_prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a95f32c",
      "metadata": {
        "id": "8a95f32c"
      },
      "source": [
        "### 3. Création de Séquences Temporelles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "75eaa530",
      "metadata": {
        "id": "75eaa530"
      },
      "outputs": [],
      "source": [
        "# Créer des séquences\n",
        "sequence_length = 60\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(scaled_prices) - sequence_length):\n",
        "    X.append(scaled_prices[i:i + sequence_length])\n",
        "    y.append(scaled_prices[i + sequence_length])\n",
        "\n",
        "X, y = np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "777ec536",
      "metadata": {
        "id": "777ec536"
      },
      "source": [
        "### 4. Division des Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "11f057df",
      "metadata": {
        "id": "11f057df"
      },
      "outputs": [],
      "source": [
        "# 80% pour l'entraînement, 10% pour la validation, 10% pour le test\n",
        "train_size = int(len(X) * 0.8)\n",
        "val_size = int(len(X) * 0.9)\n",
        "\n",
        "X_train, X_val, X_test = X[:train_size], X[train_size:val_size], X[val_size:]\n",
        "y_train, y_val, y_test = y[:train_size], y[train_size:val_size], y[val_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7badeddd",
      "metadata": {
        "id": "7badeddd"
      },
      "source": [
        "### Étape 2 : Conception du Modèle LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77b68fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77b68fe",
        "outputId": "ded9159b-05f4-4495-f481-90936ef8f8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - loss: 0.0186 - val_loss: 8.9637e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - loss: 8.2503e-04 - val_loss: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m44/93\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 7.6897e-04"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Construire le modèle LSTM\n",
        "model_lstm = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=25),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compiler le modèle\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model_lstm.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=50)\n",
        "\n",
        "# Sauvegarder le modèle entraîné\n",
        "model_lstm.save('lstm_stock_predictor.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hSE2cAFU0uvw",
      "metadata": {
        "id": "hSE2cAFU0uvw"
      },
      "source": [
        "### Générez toutes les prédictions LSTM en une seule fois :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J18nu-mO0qts",
      "metadata": {
        "id": "J18nu-mO0qts"
      },
      "outputs": [],
      "source": [
        "# Utilisez l'ensemble de données complet (X) pour générer les prédictions\n",
        "all_lstm_preds_scaled = model_lstm.predict(X)\n",
        "\n",
        "# Créez un DataFrame avec les prédictions\n",
        "# Il y aura un décalage de 'sequence_length' jours\n",
        "predictions_df = pd.DataFrame(all_lstm_preds_scaled, columns=['lstm_prediction'], index=df_aapl.index[sequence_length:])\n",
        "\n",
        "# Fusionnez les prédictions avec votre DataFrame principal\n",
        "df_aapl_with_preds = df_aapl.join(predictions_df)\n",
        "\n",
        "# Supprimez les lignes sans prédiction\n",
        "df_aapl_with_preds.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d71e83a",
      "metadata": {
        "id": "0d71e83a"
      },
      "source": [
        "# Étape 3 & 4 : Développement et Intégration du DQN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e022370",
      "metadata": {
        "id": "4e022370"
      },
      "source": [
        "### 1. Adapter l'Environnement de Trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771fd0f2",
      "metadata": {
        "id": "771fd0f2"
      },
      "outputs": [],
      "source": [
        "from gymnasium.spaces import Box\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "class TradingEnv(gym.Env):\n",
        "    \"\"\"A simple stock trading environment\"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, initial_balance=10_000):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.initial_balance = initial_balance\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Action space: 0 = Hold, 1 = Buy, 2 = Sell\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # Observation space: [balance, shares_held, net_worth, OHLCV data...]\n",
        "        # +3 for balance, shares, and net worth\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(len(self.data.columns) + 3,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # self.reset()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"Creates the observation vector for the current step.\"\"\"\n",
        "        obs = np.array([\n",
        "            self.balance,\n",
        "            self.shares_held,\n",
        "            self.net_worth,\n",
        "            *self.data.iloc[self.current_step].values\n",
        "        ], dtype=np.float32)\n",
        "        return obs\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        super().reset(seed=seed) # Important for gym compliance\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.max_net_worth = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.current_step = 0 # Start from the beginning of the data\n",
        "        self.done = False\n",
        "\n",
        "        info = {} # Gym requires returning an info dictionary\n",
        "        return self._get_observation(), info\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Execute one time step within the environment.\"\"\"\n",
        "        current_price = self.data['Close'].iloc[self.current_step]\n",
        "\n",
        "        # Action: 1 = Buy\n",
        "        if action == 1:\n",
        "            # Buy one share\n",
        "            if self.balance > current_price:\n",
        "                self.shares_held += 1\n",
        "                self.balance -= current_price\n",
        "        # Action: 2 = Sell\n",
        "        elif action == 2:\n",
        "            # Sell one share\n",
        "            if self.shares_held > 0:\n",
        "                self.shares_held -= 1\n",
        "                self.balance += current_price\n",
        "\n",
        "        # Update net worth\n",
        "        self.net_worth = self.balance + (self.shares_held * current_price)\n",
        "\n",
        "        # Move to the next time step\n",
        "        self.current_step += 1\n",
        "\n",
        "        # Define the reward (e.g., change in net worth)\n",
        "        reward = self.net_worth - self.initial_balance\n",
        "\n",
        "        # Check if the episode is done\n",
        "        if self.current_step >= len(self.data) - 1:\n",
        "            self.done = True\n",
        "\n",
        "        # Gym's step function returns 5 values\n",
        "        observation = self._get_observation()\n",
        "        terminated = self.done\n",
        "        truncated = False # Typically used if a time limit is reached, not just the end of data\n",
        "        info = {}\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        \"\"\"Render the environment to the screen (optional).\"\"\"\n",
        "        print(f'Step: {self.current_step}')\n",
        "        print(f'Balance: {self.balance:.2f}')\n",
        "        print(f'Shares held: {self.shares_held}')\n",
        "        print(f'Net Worth: {self.net_worth:.2f}')\n",
        "\n",
        "\n",
        "\n",
        "class TradingEnvWithLSTM(TradingEnv): # Hérite de votre classe TradingEnv\n",
        "    def __init__(self, data: pd.DataFrame, lstm_model_path: str, sequence_length: int, initial_balance=10_000):\n",
        "        # 1. Appeler le constructeur du parent en premier\n",
        "        # Il va initialiser self.data, etc.\n",
        "        super().__init__(data, initial_balance)\n",
        "\n",
        "        # 2. Maintenant, initialiser tous les attributs spécifiques à l'enfant\n",
        "        self.lstm_model = load_model(lstm_model_path)\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        # self.scaler et self.scaled_data dépendent de self.data, qui vient d'être créé par super()\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        self.scaled_data = self.scaler.fit_transform(self.data[['Close']].values)\n",
        "\n",
        "        # 3. Mettre à jour l'espace d'observation qui a été défini par le parent\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(len(self.data.columns) + 3 + 1,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "\n",
        "    def _get_lstm_prediction(self):\n",
        "        \"\"\"\n",
        "        Génère une prédiction de prix à partir du modèle LSTM.\n",
        "        \"\"\"\n",
        "        if self.current_step < self.sequence_length:\n",
        "            return 0 # Pas assez de données pour prédire\n",
        "\n",
        "        # Préparer la séquence pour le modèle LSTM\n",
        "        start_index = self.current_step - self.sequence_length\n",
        "        sequence = self.scaled_data[start_index:self.current_step]\n",
        "        sequence = np.array([sequence]) # Reformater pour le modèle\n",
        "\n",
        "        # Prédire et dé-normaliser la prédiction\n",
        "        predicted_scaled = self.lstm_model.predict(sequence)[0][0]\n",
        "        return predicted_scaled # On garde la valeur normalisée pour le DQN\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        Crée le vecteur d'observation enrichi avec la prédiction LSTM.\n",
        "        \"\"\"\n",
        "        lstm_pred = self._get_lstm_prediction()\n",
        "\n",
        "        obs = np.array([\n",
        "            self.balance,\n",
        "            self.shares_held,\n",
        "            self.net_worth,\n",
        "            *self.data.iloc[self.current_step].values,\n",
        "            lstm_pred # Ajouter la prédiction\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        # Call the parent's reset method to handle gym compliance\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        # Your custom logic for the child class\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.max_net_worth = self.initial_balance\n",
        "        self.done = False\n",
        "\n",
        "        # The initial step must be at least sequence_length to have a first prediction\n",
        "        self.current_step = self.sequence_length\n",
        "\n",
        "        # Return the observation AND an info dictionary\n",
        "        return self._get_observation(), {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eea5171",
      "metadata": {
        "id": "7eea5171"
      },
      "source": [
        "### 2. Entraîner l'Agent DQN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mpu3XOo3gISV",
      "metadata": {
        "id": "mpu3XOo3gISV"
      },
      "outputs": [],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19eee4c7",
      "metadata": {
        "id": "19eee4c7"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "\n",
        "# 1. Instancier l'environnement SIMPLE avec les données pré-calculées\n",
        "# C'est la méthode la plus efficace.\n",
        "env = TradingEnv(data=df_aapl_with_preds)\n",
        "\n",
        "# 2. Créer et entraîner votre agent DQN\n",
        "print(\"Création et entraînement du modèle DQN...\")\n",
        "model_dqn = DQN(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./dqn_trading_tensorboard/\")\n",
        "model_dqn.learn(total_timesteps=100_000, progress_bar=True)\n",
        "\n",
        "# 3. Sauvegarder le modèle final\n",
        "print(\"Entraînement terminé. Sauvegarde du modèle...\")\n",
        "model_dqn.save(\"dqn_lstm_trader\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6uyuldBgfcV",
      "metadata": {
        "id": "a6uyuldBgfcV"
      },
      "source": [
        "### Étape 5 : Évaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rg31Lw7yy_cM",
      "metadata": {
        "id": "Rg31Lw7yy_cM"
      },
      "outputs": [],
      "source": [
        "# Préparer les données de test\n",
        "test_data_df = df_aapl.iloc[val_size:]\n",
        "\n",
        "# Créer un environnement de test\n",
        "test_env = TradingEnvWithLSTM(\n",
        "    data=test_data_df[['Open', 'High', 'Low', 'Close', 'Volume']],\n",
        "    lstm_model_path='lstm_stock_predictor.h5',\n",
        "    sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "obs = test_env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _states = model_dqn.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = test_env.step(action)\n",
        "    test_env.render()\n",
        "\n",
        "# Calculer le ROI (Return on Investment)\n",
        "roi = ((test_env.net_worth - test_env.initial_balance) / test_env.initial_balance) * 100\n",
        "print(f\"Retour sur Investissement (ROI) final : {roi:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
